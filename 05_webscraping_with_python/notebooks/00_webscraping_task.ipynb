{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Web scraping](https://en.wikipedia.org/wiki/Web_scraping) refers to extracting data from websites. Web scraping a web page involves fetching it and extracting from it.Once fetched, then extraction can take place. The content of a page may be parsed, searched, reformatted, its data copied into a spreadsheet, and so on. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else.\n",
    "\n",
    "__Web scraping is not difficult, but how you select which data to select for your analysis is the work of art.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is a task that has to be performed responsibly so that it does not have a detrimental effect on the sites being scraped. Machines can retrieve data much quicker, in greater depth than humans, so bad scraping practices can have some impact on the performance of the site.\n",
    "\n",
    "Most websites may not have anti-scraping mechanisms since it would affect the user experience, but some sites do block scraping.\n",
    "\n",
    "> __\"With great power there must also come -- great responsibility!\"__\n",
    "\n",
    "\n",
    "\n",
    "In order to check what types of interactions are compliant wiht the data hosting website check the `robiots.txt` files.\n",
    "\n",
    "For instance amazon ([https://www.amazon.de/robots.txt](https://www.amazon.de/robots.txt)) makes it clear that it does not want to be scraped. In contrasts other sites such as [Beiersdorf](https://www.beiersdorf.de/) does not impose any restrictions (see: [https://www.beiersdorf.de/robots.txt](https://www.beiersdorf.de/robots.txt))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Task: The task is to scarpe user reviews of a Beiersdorf product from the website [beautyheaven](https://www.beautyheaven.com.au/) and analyze its content by generating a wordcloud.\n",
    "__1. Understand the structure of the website__  \n",
    "__2. Get the data__  \n",
    "__3. Analyze/visualize the data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
